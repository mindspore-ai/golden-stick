# Copyright 2022 Huawei Technologies Co., Ltd
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ============================================================================
"""TensorAddQuant."""
from __future__ import absolute_import

from mindspore.ops import operations as P
from mindspore.nn import Cell
from mindspore_gs.quantization.quant_cell import QuantCell
from mindspore_gs.quantization.layer_policy import LayerPolicy


class TensorAddQuant(QuantCell):
    r"""
    Adds fake quantized operation after TensorAdd operation.

    This part is a more detailed overview of TensorAdd operation. For more details about Quantization,
    please refer to the implementation of class of `FakeQuantWithMinMaxObserver`,
    :class:`mindspore.nn.FakeQuantWithMinMaxObserver`.

    Args:
        ema_decay (float): Exponential Moving Average algorithm parameter. Default: 0.999.
        quant_config (QuantConfig): Configures the types of quant observer and quant settings of weight and
            activation. Note that, QuantConfig is a special namedtuple, which is designed for quantization
            and can be generated by :func:`mindspore.compression.quant.create_quant_config` method.
            Default: QuantConfig with both items set to default :class:`FakeQuantWithMinMaxObserver`.

    Inputs:
        - **x1** (Tensor) - The first tensor of TensorAddQuant. The input dimension is preferably 2D or 4D.
        - **x2** (Tensor) - The second tensor of TensorAddQuant. Has the same shape with `x1`.

    Outputs:
        Tensor, with the same type and shape as the `x1`.

    Raises:
        TypeError: If `ema_decay` is not a float.
        ValueError: If the shape of `x2` is different with `x1`.

    Supported Platforms:
        ``Ascend`` ``GPU``

    Examples:
        >>> import numpy as np
        >>> import mindspore
        >>> from mindspore import Tensor, nn
        >>> add_quant = nn.TensorAddQuant()
        >>> x1 = Tensor(np.array([[1, 2, 1], [-2, 0, -1]]), mindspore.float32)
        >>> x2 = Tensor(np.ones((2, 3)), mindspore.float32)
        >>> output = add_quant(x1, x2)
        >>> print(output)
        [[ 1.9764705  3.011765   1.9764705]
         [-0.9882355  0.9882355  0.       ]]
    """

    def __init__(self, handler: Cell, policy: LayerPolicy):
        """Initialize TensorAddQuant."""
        super(TensorAddQuant, self).__init__(handler, policy)
        self.add = P.Add()

    def weight_quantizer(self):
        return None

    # pylint: disable=arguments-differ
    def core_construct(self, x1, x2):
        """construct."""
        return self.add(x1, x2)
